{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.19 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from workspace_utils import active_session \n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=256, fc2_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.bn1 = nn.BatchNorm1d(fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.bn1(self.fc1(state)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=256, fc2_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        #normalization\n",
    "        self.bn1 = nn.BatchNorm1d(fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.relu(self.bn1(self.fcs1(state)))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.05):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4        # learning rate of the actor \n",
    "LR_CRITIC = 1e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "LEARN_EVERY = 2  \n",
    "LEARN_NUM = 3  \n",
    "EPSILON = 1.0  \n",
    "EPSILON_DECAY = 0.999\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.epsilon = EPSILON\n",
    "        self.epsilon_decay=EPSILON_DECAY\n",
    "\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        #self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, shared_buffer):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        #self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        self.t_step = (self.t_step + 1) % LEARN_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(shared_buffer) > BATCH_SIZE:\n",
    "                for _ in range(LEARN_NUM):\n",
    "                    experiences = shared_buffer.sample()\n",
    "                    self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.epsilon * self.noise.sample()\n",
    "            \n",
    "            \n",
    "\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        \n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "         # --------------------- and update epsilon decay ----------------------- #\n",
    "        if self.epsilon_decay > 0:\n",
    "            self.epsilon=self.epsilon*self.epsilon_decay\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Magent():\n",
    "    def __init__(self,state_size,action_size,random_seed,num_agents):\n",
    "        self.num_agents=num_agents\n",
    "        self.mul_agent=[Agent(state_size,action_size,random_seed) for i in range(self.num_agents)]\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "\n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        #add to shared replay buffer\n",
    "        for i in range(self.num_agents):\n",
    "            self.memory.add(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "            \n",
    "        for agent in self.mul_agent:\n",
    "            agent.step(self.memory)\n",
    "\n",
    "    def act(self, states, add_noise=True):\n",
    "        new_actions =[np.squeeze(agent.act(np.expand_dims(state, axis=0), add_noise), axis=0) for agent, state in zip(self.mul_agent, states)]\n",
    "        return np.stack(new_actions)\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.mul_agent:\n",
    "            agent.reset()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "magent = Magent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=5000, max_t=1000, print_every=100):\n",
    "    \"\"\"Deep Deterministic Policy Gradient (DDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes  (int)   : maximum number of training episodes\n",
    "        max_t       (int)   : maximum number of timesteps per episode\n",
    "        print_every (int)   : interval to display results\n",
    "\n",
    "    \"\"\"\n",
    "    episode_score = []                          \n",
    "  \n",
    "    scores_window = deque(maxlen=100)             \n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]       # reset environment\n",
    "        states = env_info.vector_observations                   # get current state for each agent      \n",
    "        scores = np.zeros(num_agents)                           # initialize score for each agent\n",
    "        \n",
    "        magent.reset()\n",
    "        for t in range(max_t):\n",
    "            actions = magent.act(states, add_noise=True)         # select an action\n",
    "            env_info = env.step(actions)[brain_name]            # send actions to environment\n",
    "            next_states = env_info.vector_observations          # get next state\n",
    "            rewards = env_info.rewards                          # get reward\n",
    "            dones = env_info.local_done                         # see if episode has finished\n",
    "            # save experience to replay buffer, perform learning step at defined interval\n",
    "            #for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "            #    agent.step(state, action, reward, next_state, done)        \n",
    "            magent.step(states, actions, rewards, next_states, dones)  \n",
    "            states = next_states\n",
    "            scores += rewards        \n",
    "            if np.any(dones):                                   # exit loop when episode ends\n",
    "                break\n",
    "\n",
    "        episode_score.append(np.max(scores))           # save mean score for the episode\n",
    "        scores_window.append(np.max(scores))         # save episode score to window queue         \n",
    "        print('\\rEpisode {} Max: {:.1f}\\tWindow Avg: {:.1f}'.format(i_episode, np.max(scores), np.mean(scores_window)))\n",
    "        if (i_episode >100) and (np.mean(scores_window)>=0.5):\n",
    "            for i, agent in enumerate(magent.mul_agent):\n",
    "                torch.save(agent.actor_local.state_dict(), f'checkpoint_actor_{i}.pth')\n",
    "                torch.save(agent.critic_local.state_dict(), f'checkpoint_critic_{i}.pth')\n",
    "            #torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            #torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')   \n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))            \n",
    "            break\n",
    "    return episode_score, scores_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 2 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 3 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 4 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 5 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 6 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 7 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 8 Max: 0.0\tWindow Avg: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:96: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 10 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 11 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 12 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 13 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 14 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 15 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 16 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 17 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 18 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 19 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 20 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 21 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 22 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 23 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 24 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 25 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 26 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 27 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 28 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 29 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 30 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 31 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 32 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 33 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 34 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 35 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 36 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 37 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 38 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 39 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 40 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 41 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 42 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 43 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 44 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 45 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 46 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 47 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 48 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 49 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 50 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 51 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 52 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 53 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 54 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 55 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 56 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 57 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 58 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 59 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 60 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 61 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 62 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 63 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 64 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 65 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 66 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 67 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 68 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 69 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 70 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 71 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 72 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 73 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 74 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 75 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 76 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 77 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 78 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 79 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 80 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 81 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 82 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 83 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 84 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 85 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 86 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 87 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 88 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 89 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 90 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 91 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 92 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 93 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 94 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 95 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 96 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 97 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 98 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 99 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 100 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 101 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 102 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 103 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 104 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 105 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 106 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 107 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 108 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 109 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 110 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 111 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 112 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 113 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 114 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 115 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 116 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 117 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 118 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 119 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 120 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 121 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 122 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 123 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 124 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 125 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 126 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 127 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 128 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 129 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 130 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 131 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 132 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 133 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 134 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 135 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 136 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 137 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 138 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 139 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 140 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 141 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 142 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 143 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 144 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 145 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 146 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 147 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 148 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 149 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 150 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 151 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 152 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 153 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 154 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 155 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 156 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 157 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 158 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 159 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 160 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 161 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 162 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 163 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 164 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 165 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 166 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 167 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 168 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 169 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 170 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 171 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 172 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 173 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 174 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 175 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 176 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 177 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 178 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 179 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 180 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 181 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 182 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 183 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 184 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 185 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 186 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 187 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 188 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 189 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 190 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 191 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 192 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 193 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 194 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 195 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 196 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 197 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 198 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 199 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 200 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 201 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 202 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 203 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 204 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 205 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 206 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 207 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 208 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 209 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 210 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 211 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 212 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 213 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 214 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 215 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 216 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 217 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 218 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 219 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 220 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 221 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 222 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 223 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 224 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 225 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 226 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 227 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 228 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 229 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 230 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 231 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 232 Max: 0.0\tWindow Avg: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 233 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 234 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 235 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 236 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 237 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 238 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 239 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 240 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 241 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 242 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 243 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 244 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 245 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 246 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 247 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 248 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 249 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 250 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 251 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 252 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 253 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 254 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 255 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 256 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 257 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 258 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 259 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 260 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 261 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 262 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 263 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 264 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 265 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 266 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 267 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 268 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 269 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 270 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 271 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 272 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 273 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 274 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 275 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 276 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 277 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 278 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 279 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 280 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 281 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 282 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 283 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 284 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 285 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 286 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 287 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 288 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 289 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 290 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 291 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 292 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 293 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 294 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 295 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 296 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 297 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 298 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 299 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 300 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 301 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 302 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 303 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 304 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 305 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 306 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 307 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 308 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 309 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 310 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 311 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 312 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 313 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 314 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 315 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 316 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 317 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 318 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 319 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 320 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 321 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 322 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 323 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 324 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 325 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 326 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 327 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 328 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 329 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 330 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 331 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 332 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 333 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 334 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 335 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 336 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 337 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 338 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 339 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 340 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 341 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 342 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 343 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 344 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 345 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 346 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 347 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 348 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 349 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 350 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 351 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 352 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 353 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 354 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 355 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 356 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 357 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 358 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 359 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 360 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 361 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 362 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 363 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 364 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 365 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 366 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 367 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 368 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 369 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 370 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 371 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 372 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 373 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 374 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 375 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 376 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 377 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 378 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 379 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 380 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 381 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 382 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 383 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 384 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 385 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 386 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 387 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 388 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 389 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 390 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 391 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 392 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 393 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 394 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 395 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 396 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 397 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 398 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 399 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 400 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 401 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 402 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 403 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 404 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 405 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 406 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 407 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 408 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 409 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 410 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 411 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 412 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 413 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 414 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 415 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 416 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 417 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 418 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 419 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 420 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 421 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 422 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 423 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 424 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 425 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 426 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 427 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 428 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 429 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 430 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 431 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 432 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 433 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 434 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 435 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 436 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 437 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 438 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 439 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 440 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 441 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 442 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 443 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 444 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 445 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 446 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 447 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 448 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 449 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 450 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 451 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 452 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 453 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 454 Max: 0.2\tWindow Avg: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 455 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 456 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 457 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 458 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 459 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 460 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 461 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 462 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 463 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 464 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 465 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 466 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 467 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 468 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 469 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 470 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 471 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 472 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 473 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 474 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 475 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 476 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 477 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 478 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 479 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 480 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 481 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 482 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 483 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 484 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 485 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 486 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 487 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 488 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 489 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 490 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 491 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 492 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 493 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 494 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 495 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 496 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 497 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 498 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 499 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 500 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 501 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 502 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 503 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 504 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 505 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 506 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 507 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 508 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 509 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 510 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 511 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 512 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 513 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 514 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 515 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 516 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 517 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 518 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 519 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 520 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 521 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 522 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 523 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 524 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 525 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 526 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 527 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 528 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 529 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 530 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 531 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 532 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 533 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 534 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 535 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 536 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 537 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 538 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 539 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 540 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 541 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 542 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 543 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 544 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 545 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 546 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 547 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 548 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 549 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 550 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 551 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 552 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 553 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 554 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 555 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 556 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 557 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 558 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 559 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 560 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 561 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 562 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 563 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 564 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 565 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 566 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 567 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 568 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 569 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 570 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 571 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 572 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 573 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 574 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 575 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 576 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 577 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 578 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 579 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 580 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 581 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 582 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 583 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 584 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 585 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 586 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 587 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 588 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 589 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 590 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 591 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 592 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 593 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 594 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 595 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 596 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 597 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 598 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 599 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 600 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 601 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 602 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 603 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 604 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 605 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 606 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 607 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 608 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 609 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 610 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 611 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 612 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 613 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 614 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 615 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 616 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 617 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 618 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 619 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 620 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 621 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 622 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 623 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 624 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 625 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 626 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 627 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 628 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 629 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 630 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 631 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 632 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 633 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 634 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 635 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 636 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 637 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 638 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 639 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 640 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 641 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 642 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 643 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 644 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 645 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 646 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 647 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 648 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 649 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 650 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 651 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 652 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 653 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 654 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 655 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 656 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 657 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 658 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 659 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 660 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 661 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 662 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 663 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 664 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 665 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 666 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 667 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 668 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 669 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 670 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 671 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 672 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 673 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 674 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 675 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 676 Max: 0.0\tWindow Avg: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 677 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 678 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 679 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 680 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 681 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 682 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 683 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 684 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 685 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 686 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 687 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 688 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 689 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 690 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 691 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 692 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 693 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 694 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 695 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 696 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 697 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 698 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 699 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 700 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 701 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 702 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 703 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 704 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 705 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 706 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 707 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 708 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 709 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 710 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 711 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 712 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 713 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 714 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 715 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 716 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 717 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 718 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 719 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 720 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 721 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 722 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 723 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 724 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 725 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 726 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 727 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 728 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 729 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 730 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 731 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 732 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 733 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 734 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 735 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 736 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 737 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 738 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 739 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 740 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 741 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 742 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 743 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 744 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 745 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 746 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 747 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 748 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 749 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 750 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 751 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 752 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 753 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 754 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 755 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 756 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 757 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 758 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 759 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 760 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 761 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 762 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 763 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 764 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 765 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 766 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 767 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 768 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 769 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 770 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 771 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 772 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 773 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 774 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 775 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 776 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 777 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 778 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 779 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 780 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 781 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 782 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 783 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 784 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 785 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 786 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 787 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 788 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 789 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 790 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 791 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 792 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 793 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 794 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 795 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 796 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 797 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 798 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 799 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 800 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 801 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 802 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 803 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 804 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 805 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 806 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 807 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 808 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 809 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 810 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 811 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 812 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 813 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 814 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 815 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 816 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 817 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 818 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 819 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 820 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 821 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 822 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 823 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 824 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 825 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 826 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 827 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 828 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 829 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 830 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 831 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 832 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 833 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 834 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 835 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 836 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 837 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 838 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 839 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 840 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 841 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 842 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 843 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 844 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 845 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 846 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 847 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 848 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 849 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 850 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 851 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 852 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 853 Max: 0.3\tWindow Avg: 0.0\n",
      "Episode 854 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 855 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 856 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 857 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 858 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 859 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 860 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 861 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 862 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 863 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 864 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 865 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 866 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 867 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 868 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 869 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 870 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 871 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 872 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 873 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 874 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 875 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 876 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 877 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 878 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 879 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 880 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 881 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 882 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 883 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 884 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 885 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 886 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 887 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 888 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 889 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 890 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 891 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 892 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 893 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 894 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 895 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 896 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 897 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 898 Max: 0.0\tWindow Avg: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 899 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 900 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 901 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 902 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 903 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 904 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 905 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 906 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 907 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 908 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 909 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 910 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 911 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 912 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 913 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 914 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 915 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 916 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 917 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 918 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 919 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 920 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 921 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 922 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 923 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 924 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 925 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 926 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 927 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 928 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 929 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 930 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 931 Max: 0.3\tWindow Avg: 0.0\n",
      "Episode 932 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 933 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 934 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 935 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 936 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 937 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 938 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 939 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 940 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 941 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 942 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 943 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 944 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 945 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 946 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 947 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 948 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 949 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 950 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 951 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 952 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 953 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 954 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 955 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 956 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 957 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 958 Max: 0.0\tWindow Avg: 0.0\n",
      "Episode 959 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 960 Max: 0.2\tWindow Avg: 0.0\n",
      "Episode 961 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 962 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 963 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 964 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 965 Max: 0.1\tWindow Avg: 0.0\n",
      "Episode 966 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 967 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 968 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 969 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 970 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 971 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 972 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 973 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 974 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 975 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 976 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 977 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 978 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 979 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 980 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 981 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 982 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 983 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 984 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 985 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 986 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 987 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 988 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 989 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 990 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 991 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 992 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 993 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 994 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 995 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 996 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 997 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 998 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 999 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1000 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 1001 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1002 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1003 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1004 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1005 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1006 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 1007 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1008 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1009 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1010 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1011 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1012 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1013 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1014 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1015 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1016 Max: 0.0\tWindow Avg: 0.1\n",
      "Episode 1017 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1018 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1019 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1020 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1021 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1022 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1023 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1024 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1025 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1026 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1027 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1028 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1029 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1030 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1031 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1032 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1033 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1034 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1035 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1036 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1037 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1038 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1039 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1040 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1041 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1042 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1043 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1044 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1045 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1046 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1047 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1048 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1049 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1050 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1051 Max: 0.5\tWindow Avg: 0.1\n",
      "Episode 1052 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1053 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1054 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1055 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1056 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1057 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1058 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1059 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1060 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1061 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1062 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1063 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1064 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1065 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1066 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1067 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1068 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1069 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1070 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1071 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1072 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1073 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1074 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1075 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1076 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1077 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1078 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1079 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1080 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1081 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1082 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1083 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1084 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1085 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1086 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1087 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1088 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1089 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1090 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1091 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1092 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1093 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1094 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1095 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1096 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1097 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1098 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1099 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1100 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1101 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1102 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1103 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1104 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1105 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1106 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1107 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1108 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1109 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1110 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1111 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1112 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1113 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1114 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1115 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1116 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1117 Max: 0.1\tWindow Avg: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1118 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1119 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1120 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1121 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1122 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1123 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1124 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1125 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1126 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1127 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1128 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1129 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1130 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1131 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1132 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1133 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1134 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1135 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1136 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1137 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1138 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1139 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1140 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1141 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1142 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1143 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1144 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1145 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1146 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1147 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1148 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1149 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1150 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1151 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1152 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1153 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1154 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1155 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1156 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1157 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1158 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1159 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1160 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1161 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1162 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1163 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1164 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1165 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1166 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1167 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1168 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1169 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1170 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1171 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1172 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1173 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1174 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1175 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1176 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1177 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1178 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1179 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1180 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1181 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1182 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1183 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1184 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1185 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1186 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1187 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1188 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1189 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1190 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1191 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1192 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1193 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1194 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1195 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1196 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1197 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1198 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1199 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1200 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1201 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1202 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1203 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1204 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1205 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1206 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1207 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1208 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1209 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1210 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1211 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1212 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1213 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1214 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1215 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1216 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1217 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1218 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1219 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1220 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1221 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1222 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1223 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1224 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1225 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1226 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1227 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1228 Max: 0.3\tWindow Avg: 0.1\n",
      "Episode 1229 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1230 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1231 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1232 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1233 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1234 Max: 0.2\tWindow Avg: 0.1\n",
      "Episode 1235 Max: 0.1\tWindow Avg: 0.1\n",
      "Episode 1236 Max: 0.8\tWindow Avg: 0.2\n",
      "Episode 1237 Max: 1.5\tWindow Avg: 0.2\n",
      "Episode 1238 Max: 0.4\tWindow Avg: 0.2\n",
      "Episode 1239 Max: 0.4\tWindow Avg: 0.2\n",
      "Episode 1240 Max: 2.6\tWindow Avg: 0.2\n",
      "Episode 1241 Max: 2.6\tWindow Avg: 0.2\n",
      "Episode 1242 Max: 2.7\tWindow Avg: 0.2\n",
      "Episode 1243 Max: 2.6\tWindow Avg: 0.3\n",
      "Episode 1244 Max: 2.7\tWindow Avg: 0.3\n",
      "Episode 1245 Max: 2.7\tWindow Avg: 0.3\n",
      "Episode 1246 Max: 2.6\tWindow Avg: 0.3\n",
      "Episode 1247 Max: 0.2\tWindow Avg: 0.3\n",
      "Episode 1248 Max: 2.6\tWindow Avg: 0.4\n",
      "Episode 1249 Max: 0.3\tWindow Avg: 0.4\n",
      "Episode 1250 Max: 2.6\tWindow Avg: 0.4\n",
      "Episode 1251 Max: 0.2\tWindow Avg: 0.4\n",
      "Episode 1252 Max: 2.6\tWindow Avg: 0.4\n",
      "Episode 1253 Max: 2.7\tWindow Avg: 0.4\n",
      "Episode 1254 Max: 1.6\tWindow Avg: 0.5\n",
      "Episode 1255 Max: 0.2\tWindow Avg: 0.5\n",
      "Episode 1256 Max: 0.3\tWindow Avg: 0.5\n",
      "Episode 1257 Max: 0.2\tWindow Avg: 0.5\n",
      "Episode 1258 Max: 0.1\tWindow Avg: 0.5\n",
      "Episode 1259 Max: 0.1\tWindow Avg: 0.5\n",
      "Episode 1260 Max: 2.6\tWindow Avg: 0.5\n",
      "Episode 1261 Max: 0.5\tWindow Avg: 0.5\n",
      "Episode 1262 Max: 0.7\tWindow Avg: 0.5\n",
      "Episode 1263 Max: 0.2\tWindow Avg: 0.5\n",
      "Episode 1264 Max: 1.1\tWindow Avg: 0.5\n",
      "\n",
      "Environment solved in 1264 episodes!\tAverage Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "with active_session():\n",
    "    episode_score_, scores_window_=ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce245034a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(episode_score_)), episode_score_, label='DDPG')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
